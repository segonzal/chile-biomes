{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "\n",
    "1. Heatmap: Categorizar en Bins lat/long para crear matriz de 5x160 (10 de largo por region)\n",
    "    - Temperaturas\n",
    "    - Precipitaciones\n",
    "    - Biomas dadas las anteriores [Holdridge](https://en.wikipedia.org/wiki/Holdridge_life_zones)\n",
    "    - Alturas\n",
    "    - Equivalencia en regiones\n",
    "2. Voronoi: Cada estaci√≥n es un centroide, usar el svg d3 de chile con regiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs..."
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'cr2_prAmon_2018_stations_ghcn.txt' does not exist: b'cr2_prAmon_2018_stations_ghcn.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-59f420771b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Import Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading CSVs...'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mstations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"cr2_prAmon_2018_stations_ghcn.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m station_cols = [\n\u001b[0;32m     10\u001b[0m     \u001b[1;34m'codigo_estacion'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thesis-faces\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thesis-faces\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thesis-faces\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thesis-faces\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thesis-faces\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'cr2_prAmon_2018_stations_ghcn.txt' does not exist: b'cr2_prAmon_2018_stations_ghcn.txt'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Data\n",
    "print('Loading CSVs...', end='')\n",
    "stations = pd.read_csv(r\"cr2_prAmon_2018_stations_ghcn.txt\")\n",
    "station_cols = [\n",
    "    'codigo_estacion',\n",
    "    #'institucion',\n",
    "    #'fuente',\n",
    "    'nombre',\n",
    "    'altura',\n",
    "    'latitud',\n",
    "    'longitud',\n",
    "    #'codigo_cuenca',\n",
    "    #'nombre_cuenca',\n",
    "    #'codigo_sub_cuenca',\n",
    "    #'nombre_sub_cuenca',\n",
    "    #'inicio_observaciones',\n",
    "    #'fin_observaciones',\n",
    "    #'cantidad_observaciones',\n",
    "    #'inicio_automatica',\n",
    "]\n",
    "\n",
    "skip = lambda x: x in range(1, 15)\n",
    "\n",
    "stations = stations[station_cols]\n",
    "precipit = pd.read_csv(r\"cr2_prAmon_2018_ghcn.txt\",     skiprows=skip, dtype=str, header=None, low_memory=False).transpose()\n",
    "tempsavg = pd.read_csv(r\"cr2_tasAmon_2018_ghcn.txt\",    skiprows=skip, dtype=str, header=None, low_memory=False).transpose()\n",
    "tempsmin = pd.read_csv(r\"cr2_tasminAmon_2018_ghcn.txt\", skiprows=skip, dtype=str, header=None, low_memory=False).transpose()\n",
    "tempsmax = pd.read_csv(r\"cr2_tasmaxAmon_2018_ghcn.txt\", skiprows=skip, dtype=str, header=None, low_memory=False).transpose()\n",
    "\n",
    "precipit.rename(columns=precipit.iloc[0], inplace=True)\n",
    "tempsavg.rename(columns=tempsavg.iloc[0], inplace=True)\n",
    "tempsmin.rename(columns=tempsmin.iloc[0], inplace=True)\n",
    "tempsmax.rename(columns=tempsmax.iloc[0], inplace=True)\n",
    "\n",
    "precipit.drop(precipit.index[0], inplace=True)\n",
    "tempsavg.drop(tempsavg.index[0], inplace=True)\n",
    "tempsmin.drop(tempsmin.index[0], inplace=True)\n",
    "tempsmax.drop(tempsmax.index[0], inplace=True)\n",
    "\n",
    "print(' DONE')\n",
    "print('stations:', stations.columns.values)\n",
    "print('precipit:', precipit.columns.values)\n",
    "print('tempsavg:', tempsavg.columns.values)\n",
    "print('tempsmin:', tempsmin.columns.values)\n",
    "print('tempsmax:', tempsmax.columns.values)\n",
    "\n",
    "print('\\nUn-pivoting and setting types...', end='')\n",
    "\n",
    "# Un-pivot and set indexes (categorical reduces memory)\n",
    "precipit = pd.melt(precipit, id_vars=['codigo_estacion'], var_name='date', value_name='precipit')\n",
    "tempsavg = pd.melt(tempsavg, id_vars=['codigo_estacion'], var_name='date', value_name='tempsavg')\n",
    "tempsmin = pd.melt(tempsmin, id_vars=['codigo_estacion'], var_name='date', value_name='tempsmin')\n",
    "tempsmax = pd.melt(tempsmax, id_vars=['codigo_estacion'], var_name='date', value_name='tempsmax')\n",
    "\n",
    "# These should be floats!\n",
    "precipit['precipit'] = precipit['precipit'].astype('float32')\n",
    "tempsavg['tempsavg'] = tempsavg['tempsavg'].astype('float32')\n",
    "tempsmin['tempsmin'] = tempsmin['tempsmin'].astype('float32')\n",
    "tempsmax['tempsmax'] = tempsmax['tempsmax'].astype('float32')\n",
    "\n",
    "# Reduces memory!\n",
    "stations['codigo_estacion'] = stations['codigo_estacion'].astype('category')\n",
    "precipit['codigo_estacion'] = precipit['codigo_estacion'].astype('category')\n",
    "tempsavg['codigo_estacion'] = tempsavg['codigo_estacion'].astype('category')\n",
    "tempsmin['codigo_estacion'] = tempsmin['codigo_estacion'].astype('category')\n",
    "tempsmax['codigo_estacion'] = tempsmax['codigo_estacion'].astype('category')\n",
    "\n",
    "#To continue reducing memory, we will turn the dates into two columns with int8\n",
    "def split_date(df):\n",
    "    ndf = df['date'].str.split(\"-\", n=1, expand = True)\n",
    "    df['ano'] = ndf[0].astype('category')\n",
    "    df['mes'] = ndf[1].astype('category')\n",
    "    df.drop('date', inplace=True, axis=1)\n",
    "    \n",
    "split_date(precipit)\n",
    "split_date(tempsavg)\n",
    "split_date(tempsmin)\n",
    "split_date(tempsmax)\n",
    "\n",
    "stations.set_index(['codigo_estacion'], inplace=True)\n",
    "precipit.set_index(['codigo_estacion', 'ano', 'mes'], inplace=True)\n",
    "tempsavg.set_index(['codigo_estacion', 'ano', 'mes'], inplace=True)\n",
    "tempsmin.set_index(['codigo_estacion', 'ano', 'mes'], inplace=True)\n",
    "tempsmax.set_index(['codigo_estacion', 'ano', 'mes'], inplace=True)\n",
    "\n",
    "print(' DONE')\n",
    "print('stations:', stations.columns.values)\n",
    "print('precipit:', precipit.columns.values)\n",
    "print('tempsavg:', tempsavg.columns.values)\n",
    "print('tempsmin:', tempsmin.columns.values)\n",
    "print('tempsmax:', tempsmax.columns.values)\n",
    "\n",
    "print('\\nMerging everything...', end='')\n",
    "data = pd.merge(\n",
    "    stations,\n",
    "    pd.merge(\n",
    "        pd.merge(precipit, tempsavg, on=['codigo_estacion', 'ano', 'mes'], copy=False),\n",
    "        pd.merge(tempsmin, tempsmax, on=['codigo_estacion', 'ano', 'mes'], copy=False),\n",
    "        on=['codigo_estacion', 'ano', 'mes'], copy=False\n",
    "    ).reset_index(level=[1,2]),\n",
    "    on=['codigo_estacion'], copy=False\n",
    ").reset_index()\n",
    "print(' DONE')\n",
    "\n",
    "print('\\nReplacing -9999 with nan')\n",
    "data.replace(-9999, np.nan, inplace=True)\n",
    "\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('clima_chile.csv', index = None, header=True)\n",
    "data.to_pickle('clima_chile.xz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis faces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
